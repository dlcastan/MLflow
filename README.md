
# ğŸ“¨ Clasificador de SPAM (TFâ€‘IDF + Naive Bayes) con MLflow

Este proyecto entrena y prueba un **clasificador de SPAM** usando **TFâ€‘IDF** + **Multinomial Naive Bayes**, registrando **mÃ©tricas, artefactos y el modelo** en **MLflow**. Incluye un cuaderno de entrenamiento y un cuaderno para pruebas rÃ¡pidas del modelo.

---

## ğŸ“¦ Contenidos del repo (archivos provistos)

- `spam_dataset.csv` â†’ dataset con **1000 filas** y **2 columnas**:
  - `message_content` *(texto)*: contenido del mensaje.
  - `is_spam` *(0/1)*: etiqueta binaria (1 = SPAM, 0 = no SPAM).
- `spam_classifier_mlflow.ipynb` â†’ notebook de **entrenamiento + tracking en MLflow**.
- `test_mlflow_model.ipynb` â†’ notebook para **cargar y probar** un modelo registrado en MLflow (generado en esta sesiÃ³n).

> Si cambiÃ¡s los nombres de columna, mantenÃ© consistencia entre entrenamiento y predicciÃ³n (por ejemplo, si el pipeline espera `message_content`, usalo igual en las pruebas y en la API).

---

## ğŸ›  Requisitos

- Python 3.9+ (recomendado)
- LibrerÃ­as: `mlflow`, `scikit-learn`, `pandas`, `numpy`, `matplotlib`
- (Opcional) `conda` o `venv` para aislar el entorno

InstalaciÃ³n rÃ¡pida:
```bash
pip install mlflow scikit-learn pandas numpy matplotlib
```

---

## ğŸš€ Flujo de trabajo

1) **Entrenamiento** (en `spam_classifier_mlflow.ipynb`)
   - Carga y limpieza del dataset `spam_dataset.csv`.
   - VectorizaciÃ³n con **TFâ€‘IDF**.
   - Entrenamiento con **Multinomial Naive Bayes**.
   - **ValidaciÃ³n** (F1 con CV).
   - **EvaluaciÃ³n** en test (accuracy, precision, recall, f1).
   - **MLflow**: log de mÃ©tricas, artefactos y modelo (incluye el pipeline con TFâ€‘IDF + NB).

2) **Pruebas del modelo** (en `test_mlflow_model.ipynb`)
   - Recupera un `run_id` o toma el **Ãºltimo run** de un experimento.
   - Carga el modelo vÃ­a `mlflow.pyfunc.load_model(...)`.
   - Hace **predicciones de ejemplo** con la columna de entrada `message_content` (ajustable).
   - Si existe `test.csv`, calcula **classification_report** y **confusion_matrix**.

3) **(Opcional) Servir como API** con MLflow Model Server.

---

## â–¶ï¸ CÃ³mo entrenar y registrar en MLflow

AbrÃ­ `spam_classifier_mlflow.ipynb` y ejecutÃ¡ las celdas. Asegurate de que el logging de MLflow apunte a donde querÃ©s (por defecto, `mlruns` local).  
En el notebook se loguea el modelo bajo un subpath (tÃ­picamente `model`).

**Estructura de artefactos** (tÃ­pica):
```
mlruns/
 â””â”€ <experiment_id>/
     â””â”€ <run_id>/
         â”œâ”€ artifacts/
         â”‚   â””â”€ model/         # modelo pyfunc (incluye conda/requirements)
         â””â”€ params/metrics/...
```

---

## ğŸ§ª CÃ³mo probar el modelo (notebook listo)

UsÃ¡ `test_mlflow_model.ipynb`. PodÃ©s setear variables de entorno para personalizar:

- `MLFLOW_RUN_ID` â†’ si querÃ©s cargar un run especÃ­fico.
- `MLFLOW_EXPERIMENT_NAME` â†’ por defecto `"Default"`.
- `MLFLOW_MODEL_SUBPATH` â†’ por defecto `"model"`.
- `INPUT_COLUMN_NAME` â†’ por defecto `"text"`, **cambialo a** `"message_content"` para este dataset.
- `TEST_CSV_PATH` â†’ ruta a `test.csv` (si querÃ©s evaluar).

Ejemplo al ejecutar localmente (Linux/macOS):
```bash
export INPUT_COLUMN_NAME=message_content
jupyter lab  # o jupyter notebook
```

En Windows (PowerShell):
```powershell
$env:INPUT_COLUMN_NAME="message_content"
jupyter lab
```

---

## ğŸŒ Servir el modelo como API local

1) IdentificÃ¡ tu `MODEL_URI` (el notebook de pruebas lo imprime, suele ser `runs:/<RUN_ID>/model`).  
2) LevantÃ¡ el servidor:
```bash
mlflow models serve -m "runs:/<RUN_ID>/model" -p 5000 --enable-mlserver
```
3) ProbÃ¡ con `curl` (**nota**: ajustÃ¡ el nombre de la columna a `message_content`):
```bash
curl -X POST http://127.0.0.1:5000/invocations   -H "Content-Type: application/json"   -d '{
        "dataframe_split": {
          "columns": ["message_content"],
          "data": [
            ["Â¡Ganaste un premio! TransferÃ­ tus datos bancarios para recibirlo"],
            ["Hola, Â¿confirmamos la reuniÃ³n a las 11?"]
          ]
        }
      }'
```

La respuesta serÃ¡ algo como:
```json
{"predictions":[1,0]}
```
(donde 1 = SPAM, 0 = no SPAM, si usaste esa codificaciÃ³n).

---

## ğŸ“š Sugerencias de evaluaciÃ³n

- **MÃ©tricas**: `f1`, `precision`, `recall`, `accuracy`. Para datasets desbalanceados, priorizÃ¡ `f1`/`recall`.
- **Matriz de confusiÃ³n**: para visualizar falsos positivos/negativos.
- **Curva Precisionâ€‘Recall**: Ãºtil si el umbral de decisiÃ³n es relevante para tu caso de negocio.

---

## ğŸ§© Estructura mÃ­nima sugerida

```
.
â”œâ”€ data/
â”‚  â””â”€ spam_dataset.csv
â”œâ”€ notebooks/
â”‚  â”œâ”€ spam_classifier_mlflow.ipynb
â”‚  â””â”€ test_mlflow_model.ipynb
â”œâ”€ mlruns/              # (se crea al entrenar)
â””â”€ README.md
```

---

## â—ï¸Problemas comunes

- **Versiones de librerÃ­as**: si al cargar falla, replicÃ¡ el entorno del modelo (ver `conda.yaml`/`requirements.txt` en `artifacts/model`).  
- **Nombre de columna**: el pipeline espera una columna especÃ­fica (aquÃ­ `message_content`). Si mandÃ¡s `text`, fallarÃ¡ o predecirÃ¡ mal.  
- **Vectorizador**: asegurate de haber logueado el **pipeline completo** (TFâ€‘IDF + clasificador). Si logueÃ¡s solo el clasificador, `predict` fallarÃ¡.  
- **Dataset desbalanceado**: considerÃ¡ `class_weight`, `threshold tuning` o **resampling**.

---

## ğŸ”’ (Opcional) Registrar en Model Registry

Si usÃ¡s el Registry, podÃ©s cargar por nombre y etapa:
```python
import mlflow
model = mlflow.pyfunc.load_model("models:/spam-classifier/Production")
```

---

## ğŸ“„ Licencia

MIT (o la que elijas).

---

## ğŸ‘‹ Contacto / mantenimiento

- Autor: Diego (ajustar si corresponde).
- PRs y mejoras bienvenidas.
